{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71259f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all rows that contains missing value \n",
    "\n",
    "col_names=['DEPTH', 'DTC', 'DTS', 'CALI', 'DEN', 'DENC', 'GR', 'NEU', 'PEF',\n",
    "        'RDEP', 'RMED']    \n",
    "\n",
    "\n",
    "# remove all rows that contains missing value \n",
    "\n",
    "df1.dropna(axis=0, subset=col_names, inplace=True)\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d0f131",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pca = PCA(n_components=116)\n",
    "corr_matr=df1[1:].corr()\n",
    "#corr_matr['PHIF'].sort_values(ascending=False)\n",
    "corr_matr['SW'].sort_values(ascending=False)\n",
    "#corr_matr['VSH'].sort_values(ascending=False)\n",
    "#corr_matr\n",
    "#df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ee15c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection\n",
    "\n",
    "# define feature selection\n",
    "fs = SelectKBest(score_func=f_regression, k=11) #try different score functions\n",
    "# apply feature selection\n",
    "X_selected_PHIF = fs.fit_transform(df1.iloc[:,1:13],df1.iloc[:,14])\n",
    "filter = fs.get_support() #k features taken into account\n",
    "indexes_best_PHIF=df1.iloc[:,1:13].columns[filter]\n",
    "\n",
    "X_selected_SW = fs.fit_transform(df1.iloc[:,1:13],df1.iloc[:,15])\n",
    "filter = fs.get_support() #k features taken into account\n",
    "indexes_best_SW=df1.iloc[:,1:13].columns[filter]\n",
    "\n",
    "X_selected_VSH = fs.fit_transform(df1.iloc[:,1:13],df1.iloc[:,16])\n",
    "filter = fs.get_support() #k features taken into account\n",
    "indexes_best_VSH=df1.iloc[:,1:13].columns[filter]\n",
    "\n",
    "indexes_best_PHIF,indexes_best_PHIF,indexes_best_VSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1255be7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1_best=df1[indexes_best_PHIF] #activate it you used first option\n",
    "#clf = IsolationForest(random_state=0).fit_predict(df1_best) #better\n",
    "#df1_x_train = df1_best[clf==1]\n",
    "#df1_y_train=df1.iloc[clf==1,[14,15,16]]\n",
    "#df1_y_train\n",
    "\n",
    "\n",
    "# identify outliers in the training dataset\n",
    "#lof = LocalOutlierFactor(random_state=0)  #try other methods    #worse\n",
    "#lof_pred = lof.fit_predict(df1_best)\n",
    "#no_outliers = lof_pred != -1\n",
    "\n",
    "\n",
    "######df1_x_train= df1_best[no_outliers.values, :]\n",
    "\n",
    "\n",
    "#df1_x_train=df1_best.iloc[no_outliers==True]\n",
    "#df1_y_train=df1.iloc[no_outliers==True,[14,15,16]]\n",
    "#df1_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83cb2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,6))\n",
    "ax = Axes3D(fig, auto_add_to_figure=False)\n",
    "fig.add_axes(ax)\n",
    "\n",
    "# get colormap from seaborn\n",
    "cmap = ListedColormap(sns.color_palette(\"husl\", 256).as_hex())\n",
    "\n",
    "# plot\n",
    "sc = ax.scatter(x, y, z, s=40, c=x, marker='o', cmap=cmap, alpha=1)\n",
    "ax.set_xlabel('X Label')\n",
    "ax.set_ylabel('Y Label')\n",
    "ax.set_zlabel('Z Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca60ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def result_plot(y_predict, y_real, names = ['PHIF', 'SW', 'VSH'], clust_indexes=[],n_points=1000):\n",
    "    RMSE, R2 = [], []\n",
    "    print(names)\n",
    "    for i,name in enumerate(names):\n",
    "        print(i)\n",
    "        if isinstance(name, str)==True:\n",
    "            print(i)\n",
    "            #print(y_real.iloc[:,i])\n",
    "            print(y_predict[i])\n",
    "            RMSE.append(np.sqrt(mean_squared_error(y_real[i], y_predict[i])))\n",
    "            R2.append(r2_score(y_real[i], y_predict[i]))\n",
    "        else:\n",
    "            for j in name:\n",
    "                print(j)\n",
    "                RMSE.append(np.sqrt(mean_squared_error(y_real[i], y_predict[i])))\n",
    "                R2.append(r2_score(y_real[i], y_predict[i]))\n",
    "                \n",
    "        \n",
    "    \n",
    "    # check the accuracy of predicted data and plot the result\n",
    "    y_pred_clusts=pd.DataFrame()\n",
    "    y_true_clusts=pd.DataFrame()\n",
    "    for i,name in enumerate(names):\n",
    "        if isinstance(name, str)==True:\n",
    "            continue\n",
    "        else:\n",
    "            y_pred_clust=[]\n",
    "            y_true_clust=pd.Series([])\n",
    "            for j in name:\n",
    "                y_p=y_predict.pop(i)\n",
    "                y_t=y_real.pop(i)\n",
    "                y_pred_clust=y_pred_clust+y_p\n",
    "                y_true_clust=pd.concat([y_true_clust,y_t],axis=0)\n",
    "                print(f'iter {y_true_clust.size}')\n",
    "            y_pred_clusts=pd.concat([y_pred_clusts,pd.Series(y_pred_clust)],axis=1)\n",
    "            y_true_clusts=pd.concat([y_true_clusts,pd.Series(y_true_clust)],axis=1)\n",
    "            print(f'pred {len(y_pred_clust)},{type(y_p)}')\n",
    "            print(f'true {len(y_true_clust)},{type(y_t)}')\n",
    "    y_predict.append(y_pred_clusts,ignore_index=True)\n",
    "    y_real.append(y_true_clusts,ignore_index=True)\n",
    "    y_predict=pd.DataFrame(y_predict).T\n",
    "    y_real=pd.DataFrame(y_true).T\n",
    "    print(f' {y_real}, {y_predict}')\n",
    "    print('RMSE:', '{:.5f}'.format(np.sqrt(mean_squared_error(y_real, y_predict))))\n",
    "    for j in range(len(RMSE)):\n",
    "        print(f'    {name} : {RMSE[j]:.5f}')\n",
    "#     print(\"-\"*65)\n",
    "    \n",
    "    print( 'R^2: ', r2_score(y_real, y_predict))\n",
    "    for j in range(len(RMSE)):\n",
    "        print(f'    {name} : {R2[j]:.5f}')\n",
    "    \n",
    "    plt.subplots(nrows=3, ncols=2, figsize=(16,16))\n",
    "\n",
    "    for i,name in enumerate(names):   \n",
    "        if isinstance(name, int)==False:           \n",
    "            plt.subplot(3, 2, i*2+1)\n",
    "            plt.plot(y_real[:n_points].iloc[:,i])\n",
    "            plt.plot(y_predict[:n_points, i])\n",
    "            plt.legend(['True', 'Predicted'])\n",
    "            plt.xlabel('Sample')\n",
    "            plt.ylabel(name)\n",
    "            plt.title(name+' Prediction Comparison')\n",
    "       \n",
    "            plt.subplot(3, 2, i*2+2)\n",
    "            plt.scatter(y_real.iloc[:, i], y_predict[:, i], alpha=0.01)\n",
    "            plt.xlabel('Real Value')\n",
    "            plt.ylabel('Predicted Value')\n",
    "            plt.title(name+' Prediction Comparison')\n",
    "                   \n",
    "        else:\n",
    "            for j in name:\n",
    "                plt.subplot(3, 2, i*2+1)\n",
    "                plt.plot(y_real[:n_points].iloc[:,i])\n",
    "                plt.plot(y_predict[:n_points, i])\n",
    "                plt.legend(['True', 'Predicted'])\n",
    "                plt.xlabel('Sample')\n",
    "                plt.ylabel(name)\n",
    "                plt.title(name+' Prediction Comparison')\n",
    "\n",
    "                plt.subplot(3, 2, i*2+2)\n",
    "                plt.scatter(y_real.iloc[:, i], y_predict[:, i], alpha=0.01)\n",
    "                plt.xlabel('Real Value')\n",
    "                plt.ylabel('Predicted Value')\n",
    "                plt.title(name+' Prediction Comparison')\n",
    "                   \n",
    "\n",
    "    plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e29834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest model\n",
    "#RF = RandomForestRegressor(n_estimators=100, random_state=100)\n",
    "#RF_best = grid_search(RF, {},X_train,y_train)\n",
    "###0.9401138 k=10\n",
    "### 0.9458 k=9\n",
    "#result_plot(RF_best.predict(X_train), y_train)\n",
    "##0.00657 k=11\n",
    "#0.00715 k=10\n",
    "# 0.0072 k=9\n",
    "#RF_best.predict(X_train)\n",
    "# check the result on validation dataset only\n",
    "#result_plot(RF_best.predict(X_val), y_val)\n",
    "##0.09206 k=9\n",
    "## 0.08295 k=11\n",
    "\n",
    "#y_pred_clusts=pd.DataFrame()\n",
    "#y_true_clusts=pd.DataFrame()\n",
    "\n",
    "#y_pred_clust=[1,2,3]\n",
    "#y_true_clust=[2,3,4]\n",
    "\n",
    "#pd.concat([y_pred_clusts,pd.Series(y_pred_clust)],axis=1)\n",
    "#pd.concat([y_true_clusts,pd.Series(y_true_clust)],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bf2edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from xgboost import XGBClassifier\n",
    "#param_grid=dict(kmeans__n_clusters=range(2,30)) #2 underscores between the estimator\n",
    "#and the parameters\n",
    "#knn=KNeighborsClassifier(n_neighbors=25)\n",
    "#dbscan=DBSCAN(eps=0.05, min_samples=5)\n",
    "#knn.fit(knn.components_,dbscan.labels_[knn.core_sample_indices_])\n",
    "\n",
    "#dbscan.fit(X_train)\n",
    "#reg = MultiOutputRegressor(GradientBoostingRegressor(n_estimators=100, random_state=100))\n",
    "#pipeline=Pipeline(['model' , Birch(threshold=0.01, n_clusters=n_clust).fit_predict(X_train),\n",
    "                #   ('reg',MultiOutputRegressor(GradientBoostingRegressor(n_estimators=100,\n",
    "                    #                                                     random_state=100)))])\n",
    "\n",
    "#reg = MultiOutputRegressor(GradientBoostingRegressor(n_estimators=100, random_state=100))\n",
    "#reg = MultiOutputRegressor(XGBClassifier(n_estimators=100, random_state=100))\n",
    "#reg = MultiOutputRegressor(Ridge(random_state=100))\n",
    "#reg_best = grid_search(reg, {})\n",
    "# define the model\n",
    "\n",
    "\n",
    "'''grid = GridSearchCV(estimator=pipeline, \n",
    "                            param_grid=param_grid, \n",
    "                            scoring='r2', \n",
    "                            cv=5)\n",
    "    grid.fit(X_train, y_train)\n",
    "    print(grid.best_score_)\n",
    "\n",
    "    print(grid.best_estimator_)\n",
    "\n",
    "    #result_plot(reg_best.predict(X_train), y_train)'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
